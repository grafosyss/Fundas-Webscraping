{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes by - Kiran A Bendigeri\n",
    "Please Read 'Read me' file.\n",
    "\n",
    "1 Web scraping and parsing with Beautiful Soup 4 Introduction\n",
    "Beautiful Soup is a Python library aimed at helping programmers who are trying to scrape data from websites.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import urllib.request\n",
    "\n",
    "source = urllib.request.urlopen('https://pythonprogramming.net/parsememcparseface/').read()\n",
    "soup = bs.BeautifulSoup(source,'lxml')\n",
    "\n",
    "# title of the page\n",
    "print(soup.title)\n",
    "\n",
    "# get attributes:\n",
    "print(soup.title.name)\n",
    "\n",
    "# get values:\n",
    "print(soup.title.string)\n",
    "\n",
    "# beginning navigation:\n",
    "print(soup.title.parent.name)\n",
    "\n",
    "# getting specific values:\n",
    "print(soup.p)\n",
    "\n",
    "print(soup.find_all('p'))\n",
    "\n",
    "for paragraph in soup.find_all('p'):\n",
    "    print(paragraph.string)\n",
    "    print(str(paragraph.text))\n",
    "    \n",
    "for url in soup.find_all('a'):\n",
    "    print(url.get('href'))\n",
    "    \n",
    "print(soup.get_text())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 Navigation with Beautiful Soup 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav = soup.nav\n",
    "#we can grab the links from just the nav bar\n",
    "for url in nav.find_all('a'):\n",
    "    print(url.get('href'))\n",
    "\n",
    "#body to get the body section, then grab the .text from there\n",
    "body = soup.body\n",
    "for paragraph in body.find_all('p'):\n",
    "    print(paragraph.text)\n",
    "#div tag with the class of \"body\"    \n",
    "for div in soup.find_all('div', class_='body'):\n",
    "    print(div.text)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 Parsing tables and XML with Beautiful Soup 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.find('table')\n",
    "\n",
    "table_rows = table.find_all('tr')\n",
    "\n",
    "for tr in table_rows:\n",
    "    td = tr.find_all('td')\n",
    "    row = [i.text for i in td]\n",
    "    print(row)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's talk about parsing XML. XML uses tags much like HTML, but is slightly different. We can use a variety of libraries to parse XML, including standard library options, but, since this is a Beautiful Soup 4 tutorial, let's talk about how to do it with BS4.\n",
    "\n",
    "One of the most common reasons that you might deal with an XML document is if you are trying to scrape a sitemap for a website. PythonProgramming.net has a sitemap.xml, so we'll use that.\n",
    "\n",
    "The sitemap looks like:\n",
    "\n",
    "<urlset xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\">\n",
    "\t<url>\n",
    "\t\t<loc>\n",
    "\t\thttps://pythonprogramming.net/pickle-data-analysis-python-pandas-tutorial/\n",
    "\t\t</loc>\n",
    "\t\t<lastmod>2016-10-15</lastmod>\n",
    "\t</url>\n",
    "\t<url>\n",
    "\t\t<loc>\n",
    "\t\thttps://pythonprogramming.net/training-testing-machine-learning-tutorial/\n",
    "\t\t</loc>\n",
    "\t\t<lastmod>2016-10-15</lastmod>\n",
    "\t</url>\n",
    "</urlset>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import urllib.request\n",
    "\n",
    "source = urllib.request.urlopen('https://pythonprogramming.net/sitemap.xml').read()\n",
    "soup = bs.BeautifulSoup(source,'xml')\n",
    "#we just want to grab the urls\n",
    "for url in soup.find_all('loc'):\n",
    "    print(url.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 Scraping Dynamic Javascript Text\n",
    "Many websites will supply data that is dynamically loaded via javascript. In Python, you can make use of jinja templating and do this without javascript, but many websites use javascript to populate data. To simulate this, I have added the following code to the parsememcparseface page:\n",
    "\n",
    "<p>Javascript (dynamic data) test:</p>\n",
    "  <p class='jstest' id='yesnojs'>y u bad tho?</p>\n",
    "  <script>\n",
    "     document.getElementById('yesnojs').innerHTML = 'Look at you shinin!';\n",
    "  </script> \n",
    "The code basically takes regular paragraph tags, with the class of jstest, and initially returns the text y u bad tho?. After this, however, there is some javascript defined that will subsequently update that jstest paragraph data to be Look at you shinin!. Thus, if you are reading the javascript-updated information, you will see the shinin message. If you don't then you will be ridiculed.\n",
    "\n",
    "If you open the page in your web browser, we'll see the shinin message, so we'll try in Beautiful Soup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import urllib.request\n",
    "\n",
    "source = urllib.request.urlopen('https://pythonprogramming.net/parsememcparseface/')\n",
    "soup = bs.BeautifulSoup(source,'lxml')\n",
    "\n",
    "js_test = soup.find('p', class_='jstest')\n",
    "\n",
    "print(js_test.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
